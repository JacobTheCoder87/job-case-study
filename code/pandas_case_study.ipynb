{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Jobs case study + Word2Vec\n",
    "\n",
    "Your analytics consulting company, `Central Tendency` has recently been awarded a contract from the recruitment-advertisement tech-company `InRecruit`. You've been tasked with working on a team of other analysts in order to generate a comprehensive pipeline & analysis of real job-data that have been scraped since 11/4/2022.\n",
    "\n",
    "Mainly, `InRecruit` seeks to address the following inferential questions:\n",
    "\n",
    "* What are the most sought-after skills for data-analyst positions?\n",
    "* Which cities are hiring the most data-analysts?\n",
    "* Which companies are hiring the most data-analysts?\n",
    "* How do salary outcomes differ between remote-work & non-remote work?\n",
    "* How are salaries changing since 2022?\n",
    "* How can we predict the salary of a position based on predictive features\n",
    "* Can we train a word2vec model on the companies `description` column to learn about \"skill-clusters\"?\n",
    "\n",
    "NOTE: This dataset was too large to push to GitHub (64 MB's). Download the dataset from the following [kaggle link](https://www.kaggle.com/datasets/lukebarousse/data-analyst-job-postings-google-search).\n",
    "\n",
    "Using the full breath of your pandas, Python, statistics, and machine learning knowledge, accomplish the following as a group:\n",
    "\n",
    "**EDA**  \n",
    "\n",
    "Note that this data is highly messy! Before cleaning this dataset however, do some light exploration on the numerical and categorical columns of our dataframe. You can incorperate analyses such as:\n",
    "\n",
    "* descriptive stats\n",
    "* regex\n",
    "* data visualization\n",
    "* etc\n",
    "\n",
    "**Data Transformation**  \n",
    "\n",
    "Once you are done analyzing your dataset (and you've recognized data formatting issues), go ahead and transform your dataset! Be sure to save this newly transformed dataset for later analysis.\n",
    "\n",
    "You can incorperate\n",
    "\n",
    "* dummy encoding\n",
    "* dropping of rows & columns\n",
    "* etc\n",
    "\n",
    "**Post-Transformation Analyses**  \n",
    "\n",
    "Next, let's answer a few analytical questions with this clean dataset!\n",
    "\n",
    "* What are the most sought-after skills for data-analyst positions?\n",
    "* Which cities are hiring the most data-analysts?\n",
    "* Which companies are hiring the most data-analysts?\n",
    "* How do salary outcomes differ between remote-work & non-remote work?\n",
    "* How are salaries changing since 2022?\n",
    "\n",
    "**Data Modeling** \n",
    "\n",
    "And finally, let's answer our two predictive questions using ML models that you've built in the past!\n",
    "\n",
    "* How can we predict the salary of a position based on predictive features\n",
    "* Can we train a word2vec model on the companies `description` column to learn about \"skill-clusters\"?\n",
    "\n",
    "\n",
    "**NOTE** Notice the project is empty. You will be creating this project from scratch! Don't worry about completing the entire project in the given time frame. Instead, see if you can apply all the lessons we've gone through so far in order to do a comprehensive analysis. You can break up the work across your group! Also feel free to create multiple notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the journey of 1000 miles begins with a single step... \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
